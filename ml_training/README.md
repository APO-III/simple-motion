# ML Training Module - Sequence Generation for LSTM

Este mÃ³dulo convierte features de movimiento frame-por-frame en secuencias temporales para entrenamiento de modelos LSTM.

## ğŸ“‹ Â¿QuÃ© hace este mÃ³dulo?

Transforma datos de este formato:
```csv
video_id,frame_number,activity_label,normalized_leg_length,shoulder_vector_x,...
girar_lento,1,turning,0.971,-0.844,0.535,...
girar_lento,2,turning,0.971,-0.845,0.533,...
...
```

A este formato:
```python
X_train.shape = (44, 30, 7)  # 44 secuencias, 30 frames cada una, 7 features
y_train.shape = (44,)         # 44 labels (una por secuencia)
```

## ğŸ—ï¸ Arquitectura (Clean Architecture)

```
ml_training/
â”œâ”€â”€ domain/                   # Modelos de dominio
â”‚   â””â”€â”€ sequence.py
â”‚       - MotionSequence      # Una secuencia (30 frames Ã— 7 features)
â”‚       - SequenceDataset     # ColecciÃ³n de secuencias
â”‚       - SequenceGeneratorConfig  # ConfiguraciÃ³n
â”‚
â”œâ”€â”€ use_cases/                # LÃ³gica de negocio
â”‚   â””â”€â”€ sequence_generator.py
â”‚       - SequenceGenerator   # Genera ventanas deslizantes desde CSV
â”‚
â””â”€â”€ utils/                    # Utilidades
    â”œâ”€â”€ data_splitter.py
    â”‚   - DataSplitter        # Split train/val/test a nivel de VIDEO
    â””â”€â”€ label_encoder.py
        - LabelEncoder        # Convierte labels â†” Ã­ndices
```

## ğŸš€ Uso RÃ¡pido

### 1. Generar Secuencias

```python
from ml_training.domain.sequence import SequenceGeneratorConfig
from ml_training.use_cases.sequence_generator import SequenceGenerator

# Configurar
config = SequenceGeneratorConfig(
    window_size=30,    # 30 frames por secuencia (1 segundo @ 30 FPS)
    stride=15,         # 50% overlap entre ventanas
)

# Generar desde CSV
generator = SequenceGenerator(config=config)
dataset = generator.generate_from_csv(
    csv_path="results/raw/source3.csv",
    source_name="source3"
)

# O desde mÃºltiples sources
dataset = generator.generate_from_multiple_csvs([
    ("results/raw/source1.csv", "source1"),
    ("results/raw/source3.csv", "source3"),
])

# Ver estadÃ­sticas
dataset.print_statistics()
# Output:
# Total sequences: 91
# Sequence shape: (30, 7)
# Number of videos: 11
# Number of classes: 7
```

### 2. Split Train/Val/Test

```python
from ml_training.utils.data_splitter import DataSplitter

splitter = DataSplitter(random_seed=42)

train_dataset, val_dataset, test_dataset = splitter.split_by_video(
    dataset=dataset,
    train_ratio=0.70,
    val_ratio=0.15,
    test_ratio=0.15,
    stratify_by_label=True
)
```

**IMPORTANTE:** El split se hace a nivel de **VIDEO**, no de secuencias individuales. Esto previene data leakage (secuencias del mismo video en train y test).

### 3. Obtener Arrays para Entrenamiento

```python
# Arrays NumPy listos para LSTM
X_train = train_dataset.get_X()  # shape: (num_sequences, 30, 7)
y_train = train_dataset.get_y()  # shape: (num_sequences,)

# Para categorical crossentropy
num_classes = len(dataset.label_to_index)
y_train_cat = train_dataset.get_y_categorical(num_classes)  # shape: (num_sequences, 7)
```

## ğŸ“Š Conceptos Clave

### Ventanas Deslizantes (Sliding Windows)

```
Video con 109 frames, actividad: "standing_up"

Con window_size=30, stride=15:

Ventana 1:  frames [1-30]    â†’ Secuencia 1
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Ventana 2:  frames [16-45]   â†’ Secuencia 2
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Ventana 3:  frames [31-60]   â†’ Secuencia 3
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
...

Resultado: 7 secuencias de shape (30, 7) desde 109 frames
```

### Manejo de Cambios de Label

Si un video tiene mÃºltiples actividades:

```
Video "girar_lento":
  Frames 1-140:   "turning"        â†’ Genera ventanas aquÃ­
  Frames 141-151: "standing_still" â†’ Solo 11 frames, descartado (< 30)
```

El generador:
1. **Detecta automÃ¡ticamente** cambios de label
2. **Crea segmentos** por actividad
3. **Descarta segmentos** mÃ¡s cortos que `window_size`
4. **Genera ventanas SOLO dentro** de cada segmento (nunca mezcla labels)

## ğŸ“ˆ Resultado con tus Datos

Ejecutando `example_generate_sequences.py` con source1 + source3:

```
âœ“ Total sequences: 91
âœ“ Sequence shape: (30, 7)
âœ“ Number of videos: 11
âœ“ Number of classes: 7

Class distribution:
  sitting_down            : 9 sequences (9.89%)
  sitting_still           : 10 sequences (10.99%)
  standing_still          : 3 sequences (3.30%)
  standing_up             : 8 sequences (8.79%)
  turning                 : 19 sequences (20.88%)
  walking_away_from_camera: 19 sequences (20.88%)
  walking_towards_camera  : 23 sequences (25.27%)

Split:
  Train: 44 sequences from 6 videos
  Test:  47 sequences from 5 videos
```

## ğŸ”§ ConfiguraciÃ³n

### SequenceGeneratorConfig

```python
config = SequenceGeneratorConfig(
    window_size=30,           # Frames por secuencia
    stride=15,                # Salto entre ventanas
    min_segment_length=30,    # MÃ­nimo de frames para procesar un segmento
    feature_columns=[         # Columnas del CSV a usar
        "normalized_leg_length",
        "shoulder_vector_x",
        "shoulder_vector_z",
        "ankle_vector_x",
        "ankle_vector_z",
        "average_hip_angle",
        "average_knee_angle"
    ]
)
```

**Recomendaciones:**
- `window_size=30` â†’ 1 segundo @ 30 FPS (captura movimientos completos)
- `stride=15` â†’ 50% overlap (mÃ¡s datos, transiciones suaves)
- `stride=10` â†’ 66% overlap (aÃºn mÃ¡s datos si tienes pocos videos)

## ğŸ“ Archivos de Salida

### label_encoder.json

```json
{
  "label_to_index": {
    "sitting_down": 0,
    "standing_up": 3,
    "turning": 4,
    ...
  },
  "index_to_label": {
    "0": "sitting_down",
    "3": "standing_up",
    ...
  },
  "num_classes": 7
}
```

**Uso:** Cargar este archivo durante inferencia para decodificar predicciones del modelo.

```python
from ml_training.utils.label_encoder import LabelEncoder

encoder = LabelEncoder.load("output/label_encoder.json")
predicted_index = 4
activity = encoder.decode(predicted_index)  # "turning"
```

## âš ï¸ Consideraciones Importantes

### 1. Dataset PequeÃ±o

Con solo 11 videos y 91 secuencias:
- El split 70/15/15 puede resultar en 0 videos para validaciÃ³n
- **SoluciÃ³n:** Usar mÃ¡s videos de source2, o ajustar ratios (80/10/10)

### 2. Desbalance de Clases

```
standing_still: 3 sequences (3.30%)   â† MUY POCO
turning:        19 sequences (20.88%)  â† OK
```

**Soluciones:**
- Procesar mÃ¡s videos con actividades poco frecuentes
- Usar `class_weights` en el entrenamiento LSTM
- Data augmentation (variaciones de velocidad, ruido)

### 3. Frames Descartados

El generador descarta:
- Segmentos < 30 frames (muy cortos)
- Frames en transiciones entre actividades

```
âš  Skipped segment [1-13] 'sitting_down': too short (13 frames)
âš  Skipped segment [264-290] 'turning': too short (27 frames)
```

**Esto es correcto** para mantener pureza de labels, pero significa que pierdes ~20-30% de frames.

## ğŸ¯ PrÃ³ximos Pasos

1. **Procesar source2** para tener mÃ¡s datos
2. **Implementar LSTM trainer** en `ml_training/use_cases/lstm_trainer.py`
3. **Definir arquitectura LSTM** en `ml_training/infrastructure/keras_lstm_model.py`
4. **Entrenar modelo** con las secuencias generadas

## ğŸ“– Ejemplos

Ver `example_generate_sequences.py` para un ejemplo completo de uso.

```bash
python example_generate_sequences.py
```

## ğŸ§ª Tests

```bash
pytest ml_training/tests/
```

(Nota: Tests pendientes de implementar)
